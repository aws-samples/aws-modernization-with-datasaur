---
title: "Getting Started with the LLM Playground" # MODIFY THIS TITLE
chapter: true
weight: 1 # MODIFY THIS VALUE TO REFLECT THE ORDERING OF THE MODULES
---

# Getting Started with the LLM Playground <!-- MODIFY THIS HEADING -->
## Step 1: Create Your LLM Playground


![Create LLM Playground](/images/step1.png) 

Create LLM Playground
- Click on "Create Playground" to establish your dedicated workspace.
- You can assign a descriptive name to your playground for easy identification.

## Step 2: Configure the Playground Application

![Configure LLM Playground](/images/step2.png) 

Configure the Application
- Access the "Models Configuration" section within your playground.
- You can adjust various parameters for the connected LLM model, such as temperature or token settings.
- Experiment with different configurations to observe their impact on the model's responses. 

## Step 3: Run Prompts
![Run Prompts](/images/step3.png) 

- Enter your desired prompt within the designated area.
- This prompt can be a question, a task instruction, or any text input you want the LLM model to process.
- Click "Run" to trigger the model's response based on your prompt.

### RAG Example: Healthcare Assistant
Here is how Vector Store can streamline the development of a Retrieval-Augmented Generation (RAG) based Healthcare Assistant in LLM Labs:

Create the [LLM Playground](https://docs.datasaur.ai/llm-projects/llm-playground) with the User Instruction and System Instruction you've prepared.

![Healthcare Assistant](/images/healthcareassistant.png) 

From the Vector stores dropdown, select the vector store you created.

![none](/images/none.png) 
![demo](/images/demo.png) 
![prompt1](/images/prompt1.png) 
You can also view the corresponding chunks from the vector store and the source.

![ha2](/images/ha2.png) 
**This is just one example!** Vector Store empowers you to build various LLM applications that rely on efficient retrieval of semantically related information.
